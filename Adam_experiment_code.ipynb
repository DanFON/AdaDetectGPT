{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanFON/AdaDetectGPT/blob/main/Adam_experiment_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0VdGZNcX-9B",
        "outputId": "acc5f038-a15b-410d-926c-3717110e6c77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We5CuEh1ZZpS"
      },
      "source": [
        "Installing dependencies and importing libraries which are needed for data processing, visualisation and evaluation using performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4esJzdaBeAp4",
        "outputId": "50dbb1f9-5611-4276-b14c-504845d8be26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nest-asyncio\n",
        "!pip install google.colab\n",
        "!pip install opencv-python\n",
        "!pip install opencv-contrib-python\n",
        "import matplotlib.pyplot as chart\n",
        "import seaborn as sns\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.models import model_from_json\n",
        "import cv2\n",
        "import os as opsys\n",
        "import numpy as NUMPY\n",
        "from tqdm import tqdm\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from tensorflow.keras.optimizers import SGD , Adam , Adadelta, Adagrad, Adamax, Nadam, RMSprop\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "#from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.layers import Dropout as drop\n",
        "from keras.layers import Input, Add, Dense, ZeroPadding2D,  Flatten\n",
        "from keras.layers import ZeroPadding2D as ZPad\n",
        "from keras.layers import Activation as non_linear_activation\n",
        "from keras.layers import Conv2D as CNV_layer\n",
        "from keras.layers import BatchNormalization as batch_norm\n",
        "from keras.layers import MaxPooling2D as MP\n",
        "from keras.layers import AveragePooling2D as AP\n",
        "from keras.preprocessing import image\n",
        "from keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import to_categorical , plot_model\n",
        "from tensorflow.keras.layers import LeakyReLU, ELU, ReLU\n",
        "from keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hChkPP8SnnS"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTNcb_GJ8D34"
      },
      "source": [
        "Reads images from the uploaded files, checks if they are loaded and resized correctly and assigns labels, using tqdm for progress bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ScYvThKeyga"
      },
      "outputs": [],
      "source": [
        "#def data_reading(dir, labels, img_size):\n",
        "#    d = []\n",
        "#    for L in labels:\n",
        "#        P , class_num = opsys.path.join(dir, L), labels.index(L)\n",
        "#        for I in tqdm(opsys.listdir(P)): # Added tqdm for progress bar\n",
        "#            try:\n",
        "#                img_path = opsys.path.join(P, I)\n",
        "#                img = cv2.imread(img_path)\n",
        "#                if img is not None: # Check if image loaded successfully\n",
        "#                    resized_img = cv2.resize(img, (img_size, img_size))\n",
        "#                    if resized_img is not None and resized_img.shape[0] > 0 and resized_img.shape[1] > 0: # Check if resize was successful and image is not empty\n",
        "#                        d.append([resized_img, class_num])\n",
        "#                    else:\n",
        "#                        print(f\"Skipping image {img_path} due to invalid resize.\")\n",
        "#                else:\n",
        "#                    print(f\"Skipping image {img_path} as it could not be loaded.\")\n",
        "#            except Exception as e:\n",
        "#                print(f\"Error processing image {img_path}: {e}\")\n",
        "#    return NUMPY.array(d, dtype=object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZ_gwonn_iMF"
      },
      "outputs": [],
      "source": [
        "#def data_reading(dir, labels, img_size):\n",
        "#    d = []\n",
        "#    output_labels = []\n",
        "#    for category in labels:\n",
        "#        path = os.path.join(dir, category)\n",
        "#        class_num = labels.index(category)\n",
        "#        for img in os.listdir(path):\n",
        "#            img_array = cv2.imread(os.path.join(path, img))\n",
        "#            if img_array is not None:\n",
        "#                img_array = cv2.resize(img_array, (img_size, img_size))\n",
        "#                d.append(img_array)\n",
        "#                output_labels.append(class_num)\n",
        "#    return NUMPY.array(d), NUMPY.array(output_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f4mYBxg-HsC"
      },
      "source": [
        "Another version of the data_reding function that has additional error handling and logging\n",
        "#check if still needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMp2Rbin7Ti3"
      },
      "outputs": [],
      "source": [
        "def data_reading(dir, labels, img_size):\n",
        "    images = []\n",
        "    image_labels = []\n",
        "    for L in labels:\n",
        "        folder_path = opsys.path.join(dir, L)\n",
        "        print(f\"Searching in: {folder_path}\")\n",
        "\n",
        "        if not opsys.path.exists(folder_path):\n",
        "            print(f\" Folder not found: {folder_path}\")\n",
        "            continue\n",
        "\n",
        "        for I in opsys.listdir(folder_path):\n",
        "            try:\n",
        "                img = cv2.imread(opsys.path.join(folder_path, I))\n",
        "                if img is None:\n",
        "                    print(f\" Could not read image: {I}\")\n",
        "                    continue\n",
        "                resized = cv2.resize(img, (img_size, img_size))\n",
        "                images.append(resized)\n",
        "                image_labels.append(labels.index(L))\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {I}: {e}\")\n",
        "\n",
        "    print(f\" Loaded {len(images)} items from {dir}\")\n",
        "    return NUMPY.array(images), NUMPY.array(image_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAfsMvNqKg9n"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/chest_xray.zip'\n",
        "extract_path = '/content/chest_xray'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D94U7Oj2NDoo"
      },
      "outputs": [],
      "source": [
        "!ls /content/chest_xray/__chest_xray/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwZuiT5pVKJ3"
      },
      "source": [
        "Displaying images with their corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSOiPVtbfGC9"
      },
      "outputs": [],
      "source": [
        "def display(information):\n",
        "\n",
        "    chart.figure(figsize = (7,7))\n",
        "    chart.imshow(information[0][0], cmap='gray')\n",
        "    chart.title(labels[information[0][1]])\n",
        "\n",
        "    chart.figure(figsize = (7,7))\n",
        "    chart.imshow(information[-1][0], cmap='gray')\n",
        "    chart.title(labels[information[-1][1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fy2ckqYX8oJc"
      },
      "source": [
        "Using data_reading function to load training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPYl-vEmfOSq"
      },
      "outputs": [],
      "source": [
        "labels , img_size = ['NORMAL' , 'PNEUMONIA'] , 224\n",
        "\n",
        "# Modified the call to data_reading to match the updated function signature\n",
        "train, train_labels = data_reading(\"/content/chest_xray/chest_xray/train\", labels, img_size)\n",
        "test, test_labels = data_reading(\"/content/chest_xray/chest_xray/test\", labels, img_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUXQBjcb81U6"
      },
      "source": [
        "To visualise distribution of classes in datasets using seaborn and matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQAmFuTXmCtq"
      },
      "outputs": [],
      "source": [
        "#import seaborn as sns\n",
        "#import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "def get_visualization(images, labels_array):\n",
        "  label_map = {0: 'NORMAL', 1: 'PNEUMONIA'}\n",
        "  labels = [label_map[item] for item in labels_array]\n",
        "\n",
        "  sns.set(style=\"whitegrid\")\n",
        "  chart.figure(figsize=(10, 6))\n",
        "  sns.countplot(x=labels)\n",
        "\n",
        "  chart.title(\"Training Set Class Distribution\", fontsize=16)\n",
        "  chart.xlabel(\"Pneumonia, Normal\")\n",
        "  chart.ylabel(\"count\", fontsize=12)\n",
        "  chart.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayIe5GKP7vKx"
      },
      "outputs": [],
      "source": [
        "#counts = Counter(labels)\n",
        "print(Counter(train_labels))\n",
        "print(Counter(test_labels))\n",
        "#should give the number of instances of each class, check why it's only 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0oaz2oyyOF-"
      },
      "outputs": [],
      "source": [
        "print(labels[:30])\n",
        "print(len(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQPkP3IT0xio"
      },
      "outputs": [],
      "source": [
        "labels = []\n",
        "path = '/content/chest_xray/chest_xray/train' # Use the correct path variable\n",
        "\n",
        "for folder in os.listdir(path):\n",
        "    folder_path = os.path.join(path, folder)\n",
        "    for file in os.listdir(folder_path):\n",
        "        labels.append(folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEw_j4HG7s0W"
      },
      "outputs": [],
      "source": [
        "!ls /content/chest_xray/chest_xray/train/PNEUMONIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCnuOcnS8MkK"
      },
      "outputs": [],
      "source": [
        "!find /content/chest_xray -type f | grep .jpeg | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJcLeVQfrLZJ"
      },
      "outputs": [],
      "source": [
        "zip_path = '/content/drive/MyDrive/lung_disease_undersampling.zip'\n",
        "extract_path = '/content/lung_disease_undersampling'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS3Jo7WnU1k6"
      },
      "source": [
        "attempt only using one validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kl2d3BZjyIzF"
      },
      "outputs": [],
      "source": [
        "#zip_path = '/content/drive/MyDrive/lung_disease_undersampling_.zip'\n",
        "#extract_path = '/content/lung_disease_undersampling_'\n",
        "\n",
        "#with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "#  zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUUj3JUuqrtf"
      },
      "outputs": [],
      "source": [
        "!find /content/lung_disease_undersampling -type f | grep .jpeg | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8EqEyPmyjyO"
      },
      "outputs": [],
      "source": [
        "#!find /content/lung_disease_undersampling_ -type f | grep .jpeg | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f7qD23TxwNI"
      },
      "outputs": [],
      "source": [
        "print(opsys.listdir('/content/lung_disease_undersampling'))\n",
        "#print(opsys.listdir('/content/lung_disease_undersampling_'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rg6QE_Dn1htU"
      },
      "outputs": [],
      "source": [
        "#from inspect import classify_class_attrs\n",
        "#import re, shutil\n",
        "\n",
        "#def clean_copy(src_root, dst_root):\n",
        " #   opsys.makedirs(opsys.path.join(dst_root, 'NORMAL'), exist_ok=True)\n",
        "  #  opsys.makedirs(opsys.path.join(dst_root, 'PNEUMONIA'), exist_ok=True)\n",
        "\n",
        "   # patt_norm = re.compile(r'NORMAL', re.I)\n",
        "    #patt_pneu = re.compile(r'(BACTERIA|VIRUS|PNEUMONIA)', re.I)\n",
        "\n",
        "    #copied = 0\n",
        "    #flagged = []\n",
        "\n",
        "    #for cls in ['NORMAL', 'PNEUMONIA']:\n",
        "     #   src_cls = opsys.path.join(src_root, cls)\n",
        "      #  if not opsys.path.isdir(src_cls):\n",
        "#            print(\"Missing:\", src_cls); continue\n",
        "\n",
        "       # for f in opsys.listdir(src_cls):\n",
        "        #    src = opsys.path.join(src_cls, f)\n",
        "         #   if not opsys.path.isfile(src):\n",
        "              #  continue\n",
        "          #  name = f.lower()\n",
        "\n",
        "           # if patt_norm.search(name) and not patt_pneu.search(name):\n",
        "               # label = 'NORMAL'\n",
        "            #elif patt_pneu.search(name) and not patt_norm.search(name):\n",
        "                #label = 'PNEUMONIA'\n",
        "            #else:\n",
        "             #   label = cls\n",
        "              #  flagged.append((cls, f))\n",
        "\n",
        "          #  dst = opsys.path.join(dst_root, label, f)\n",
        "           # shutil.copy2(src,dst)\n",
        "            #copied += 1\n",
        "\n",
        "    #print(f\"Copied {copied} files into {dst_root}. Ambiguous files: {len(flagged)}\")\n",
        "    #return flagged\n",
        "\n",
        "#flags1 = clean_copy('/content/lung_disease_undersampling/lung_disease_undersampling', '/content/lung_disease_val_clean')\n",
        "#flags2 = clean_copy('/content/lung_disease_undersampling_/lung_disease_undersampling', '/content/lung_disease_val2_clean')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NA89nlK-XdZB"
      },
      "source": [
        "COME BACK TO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOgZOlhv9mDL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "val_dataset = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"lung_disease_undersampling/lung_disease_undersampling\",\n",
        "    labels=\"inferred\",\n",
        "    label_mode=\"binary\",\n",
        "    image_size=(224, 224),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "#val_ds2 = tf.keras.utils.image_dataset_from_directory(\n",
        "#    \"lung_disease_undersampling_/lung_disease_undersampling_\",\n",
        "#    labels=\"inferred\",\n",
        "#    label_mode=\"binary\",\n",
        "#    image_size=(224, 224),\n",
        "#    batch_size=32\n",
        "#)\n",
        "\n",
        "#val_images, val_labels = data_reading('/content/lung_disease_undersampling/lung_disease_undersampling', labels, img_size)\n",
        "#val2_images, val2_labels = data_reading('/content/lung_disease_undersampling_/lung_disease_undersampling', labels, img_size)\n",
        "#test_images, test_labels = data_reading('/content/lung_disease_undersampling_/lung_disease_undersampling/test', labels, img_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Py4Xfwx9oPdw"
      },
      "outputs": [],
      "source": [
        "for images, labels in val_dataset.take(1):\n",
        "    print(labels.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80loDsuH6Xxr"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "  print(train[i][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH74LA6VHItf"
      },
      "outputs": [],
      "source": [
        "get_visualization(train, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrahIUx_pmmk"
      },
      "source": [
        "Imbalanced dataset so model may have more false positives, should use class weights and install imbalanced-learn library to handle the class imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bj-mb512pWqW"
      },
      "outputs": [],
      "source": [
        "#!pip install -U imbalanced-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlcoDLIoHPKe"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv\n",
        "#print(df['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzVcnsTUx50v"
      },
      "outputs": [],
      "source": [
        "train_path = '/content/chest_xray/chest_xray/train'\n",
        "#val_combined = val_ds.concatenate(val_ds2)\n",
        "#val_path = '/content/dataset/val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9MKG75dPd08"
      },
      "outputs": [],
      "source": [
        "print(\"Size of training data\",len(train))\n",
        "print(\"Size of testing data\",len(test))\n",
        "print(\"Size of validation data\", len(val_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOxLdIaFpkKb"
      },
      "outputs": [],
      "source": [
        "print(\"Training images:\", len(train))\n",
        "print(\"Testing images:\", len(test))\n",
        "print(\"Validation images\", len(val_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVgLAP3ExkN2"
      },
      "source": [
        "COME BACK TO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaEMy78VCzXr"
      },
      "outputs": [],
      "source": [
        "def display_one_normal_and_one_pneumonia(information, labels):\n",
        "    normal_img, pneumonia_img = None, None\n",
        "\n",
        "    for img, label in information:\n",
        "        # Corrected the comparison to use the integer label to access the class name\n",
        "        if labels[label] == \"NORMAL\" and normal_img is None:\n",
        "            normal_img = (img, label)\n",
        "        elif labels[label] == \"PNEUMONIA\" and pneumonia_img is None:\n",
        "            pneumonia_img = (img, label)\n",
        "        if normal_img and pneumonia_img:\n",
        "          break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMJTYnHNrbuh"
      },
      "outputs": [],
      "source": [
        "#display(information)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcXAQz6qPqHl"
      },
      "outputs": [],
      "source": [
        "#pairs = list(zip(train, train_labels))\n",
        "#display_one_normal_and_one_pneumonia(pairs, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbY4r4JOSvOQ"
      },
      "outputs": [],
      "source": [
        "def add_variable_guassian_noise(img, mean=0, sigma_range=(0.01, 0.05)):\n",
        "  row, col, ch = img.shape\n",
        "\n",
        "  sigma = NUMPY.random.uniform(sigma_range[0], sigma_range[1])\n",
        "  #sigma = 0.01\n",
        "  #sigma = 0.05\n",
        "\n",
        "  gauss = NUMPY.random.normal(mean, sigma, (row, col, ch))\n",
        "  noisy = img + gauss\n",
        "  noisy = NUMPY.clip(noisy, 0., 1.)\n",
        "  return noisy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6foJVVGxwf9"
      },
      "outputs": [],
      "source": [
        "def apply_clahe(img):\n",
        "\n",
        "    if img.max() <= 1.0:\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "    else:\n",
        "        img = img.astype(np.uint8)\n",
        "\n",
        "    if img.ndim == 3 and img.shape[-1] == 3:\n",
        "        img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        img_gray = img\n",
        "\n",
        "\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "    img_clahe = clahe.apply(img_gray)\n",
        "\n",
        "    img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    img_clahe = img_clahe.astype(np.float32) / 255\n",
        "    return img_clahe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTjMYvmEzSyZ"
      },
      "outputs": [],
      "source": [
        "def preprocessing_pipeline(img, training=False):\n",
        "    img = apply_clahe(img)\n",
        "    if training:\n",
        "        img = add_variable_guassian_noise(img)\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4BAbfHHANlW"
      },
      "source": [
        "Data augmentation by applying transformations to training data to increase diversity of training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jp6puEHkTLNT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=lambda x: preprocessing_pipeline(x, training=True),\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    #shear_range=0.2,\n",
        "    brightness_range=(0.9,1.1),\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(preprocessing_function=lambda x: preprocessing_pipeline(x, training=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA3mVokwTUia"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\"chest_xray/chest_xray/train\",target_size=(224, 224),batch_size=32,shuffle=True,class_mode='binary')\n",
        "val_generator = val_test_datagen.flow_from_directory(\"lung_disease_undersampling/lung_disease_undersampling\",target_size=(224,224),batch_size=32,shuffle=False,class_mode='binary')\n",
        "#val2_generator = val_datagen.flow_from_directory(\"lung_disease_undersampling_/lung_disease_undersampling\", target_size=(224,224), batch_size=32, shuffle=False,class_mode='binary')\n",
        "test_generator = val_test_datagen.flow_from_directory(\"chest_xray/chest_xray/test\",target_size=(224,224),batch_size=32,shuffle=False,class_mode='binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZr9-kVdrg82"
      },
      "outputs": [],
      "source": [
        "print(train_generator.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bB0pVW7paXRL"
      },
      "outputs": [],
      "source": [
        "#import numpy as np\n",
        "#from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#y_train = [item[1] for item in train] # This line is not needed with the current data structure\n",
        "#X = NUMPY.array([item[0] for item in train]) # This line is not needed with the current data structure\n",
        "#y = NUMPY.array([item[1] for item in train]) # This line is not needed with the current data structure\n",
        "\n",
        "# Use the existing train_images and train_labels variables\n",
        "#X_train, X_test, y_train, y_test = train_test_split(train_images, train_labels, test_size=0.2, stratify=train_labels, random_state=42)\n",
        "\n",
        "# Normalization should be done after splitting\n",
        "#X_train = X_train / 255.0\n",
        "#X_test = X_test / 255.0\n",
        "\n",
        "labels = train_generator.classes\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=NUMPY.unique(labels), y=labels)\n",
        "\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "print(\"Class weights:\", class_weights)\n",
        "\n",
        "# The model fitting should be done using the data generators instead of the split arrays.\n",
        "# history = model.fit(\n",
        "#     X_train, y_train,\n",
        "#     validation_data=(X_test, y_test),\n",
        "#     epochs=50,\n",
        "#     batch_size=32,\n",
        "#     class_weight=class_weights\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jSKplXhWQfx"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "class_counts = Counter(train_generator.classes)\n",
        "print(\"Class distribution in training set:\", class_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLmui9boUEiA"
      },
      "source": [
        "**ResNet 50 Implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnARKwCXAj3i"
      },
      "source": [
        "Identify block to add skip connections (helps with gradient flow)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asc-xOPmUHe1"
      },
      "outputs": [],
      "source": [
        "def IB(L, f, filters, stage, block):\n",
        "\n",
        "    Filter1, Filter2, Filter3 = filters\n",
        "\n",
        "    L_shortcut = L\n",
        "\n",
        "    L = CNV_layer(filters=Filter1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name='res' + str(stage) + block + '_branch' + '2a', kernel_initializer=glorot_uniform(seed=0))(L)\n",
        "    L = batch_norm(axis=3, name='bn' + str(stage) + block + '_branch' + '2a')(L)\n",
        "    L = ReLU()(L)\n",
        "\n",
        "    L = CNV_layer(filters=Filter2, kernel_size=(f, f), strides=(1, 1), padding='same', name='res' + str(stage) + block + '_branch' + '2b', kernel_initializer=glorot_uniform(seed=0))(L)\n",
        "    L = batch_norm(axis=3, name='bn' + str(stage) + block + '_branch' + '2b')(L)\n",
        "    L = ReLU()(L)\n",
        "\n",
        "    L = CNV_layer(filters=Filter3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name='res' + str(stage) + block + '_branch' + '2c', kernel_initializer=glorot_uniform(seed=0))(L)\n",
        "    L = batch_norm(axis=3, name='bn' + str(stage) + block + '_branch' + '2c')(L)\n",
        "\n",
        "    L = Add()([L, L_shortcut])# SKIP Connection\n",
        "    L = ReLU()(L)\n",
        "\n",
        "    return L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trboxcg6Aqsw"
      },
      "source": [
        "Adding convolution layers (convolutional block) with downsampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRiiEwqFUUJm"
      },
      "outputs": [],
      "source": [
        "def CB(L, f, filters, stage, block, s=2):\n",
        "\n",
        "\n",
        "    Filter1, Filter2, Filter3 = filters\n",
        "\n",
        "    L_shortcut = L\n",
        "\n",
        "    L = CNV_layer(filters=Filter1, kernel_size=(1, 1), strides=(s, s), padding='valid', name='res' + str(stage) + block + '_branch' + '2a', kernel_initializer=glorot_uniform(seed=0))(L)\n",
        "    L = batch_norm(axis=3, name='bn' + str(stage) + block + '_branch' + '2a')(L)\n",
        "    L = ReLU()(L)\n",
        "\n",
        "    L = CNV_layer(filters=Filter2, kernel_size=(f, f), strides=(1, 1), padding='same', name='res' + str(stage) + block + '_branch' + '2b', kernel_initializer=glorot_uniform(seed=0))(L)\n",
        "    L = batch_norm(axis=3, name='bn' + str(stage) + block + '_branch' + '2b')(L)\n",
        "    LookupError = ReLU()(L)\n",
        "\n",
        "    L = CNV_layer(filters=Filter3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name='res' + str(stage) + block + '_branch' + '2c', kernel_initializer=glorot_uniform(seed=0))(L)\n",
        "    L = batch_norm(axis=3, name='bn' + str(stage) + block + '_branch' + '2c')(L)\n",
        "\n",
        "    L_shortcut = CNV_layer(filters=Filter3, kernel_size=(1, 1), strides=(s, s), padding='valid', name='res' + str(stage) + block + '_branch' + '1', kernel_initializer=glorot_uniform(seed=0))(L_shortcut)\n",
        "    L_shortcut = batch_norm(axis=3, name='bn' + str(stage) + block + '_branch' + '1')(L_shortcut)\n",
        "\n",
        "    L = Add()([L, L_shortcut])\n",
        "    L = ReLU()(L)\n",
        "\n",
        "    return L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk7hW2u3A1sK"
      },
      "source": [
        "Defining the model by combining IB and CB block to create the ResNet50 architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emOvdI1JUjH7"
      },
      "outputs": [],
      "source": [
        "def ResNet50(input_shape=(224, 224, 3)):\n",
        "\n",
        "    L_input = Input(input_shape)\n",
        "\n",
        "    L = ZPad((3, 3))(L_input)\n",
        "\n",
        "    L = CNV_layer(64, kernel_size=(7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(L)\n",
        "    L = batch_norm(axis=3, name='bn_conv1')(L)\n",
        "    L = ReLU()(L)\n",
        "    L = MP(pool_size=(3, 3), strides=(2, 2))(L)\n",
        "\n",
        "    L = CB(L, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n",
        "    L = IB(L, 3, [64, 64, 256], stage=2, block='b')\n",
        "    L = IB(L, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "\n",
        "    L = CB(L, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n",
        "    L = IB(L, 3, [128, 128, 512], stage=3, block='b')\n",
        "    #X = IB(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    L = IB(L, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    L = CB(L, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n",
        "    L = IB(L, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    L = IB(L, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    #X = IB(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    #X = IB(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    L = IB(L, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    L = CB(L, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n",
        "    L = IB(L, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    #X = IB(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    L = AP(pool_size=(2, 2), padding='same')(L)\n",
        "\n",
        "    model = Model(inputs=L_input, outputs=L, name='ResNet50')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f40w5JLdUoFE"
      },
      "outputs": [],
      "source": [
        "adapt = ResNet50(input_shape=(224, 224, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qfy6RNrf5Bc"
      },
      "outputs": [],
      "source": [
        "adapt_design = adapt.output\n",
        "adapt_design = Flatten()(adapt_design)\n",
        "adapt_design = Dense(256, name='fc1',kernel_initializer=glorot_uniform(seed=0),kernel_regularizer=l2(0.01))(adapt_design)\n",
        "adapt_design = batch_norm()(adapt_design)\n",
        "adapt_design = ReLU()(adapt_design)\n",
        "adapt_design = drop(rate = 0.5)(adapt_design)\n",
        "adapt_design = Dense(128, name='fc2',kernel_initializer=glorot_uniform(seed=0),kernel_regularizer=l2(0.01))(adapt_design)\n",
        "adapt_design = batch_norm()(adapt_design)\n",
        "adapt_design = ReLU()(adapt_design)\n",
        "adapt_design = drop(rate = 0.5)(adapt_design)\n",
        "output = Dense( 1,activation='sigmoid', name='fc3',kernel_initializer=glorot_uniform(seed=0))(adapt_design)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUyhjBFqUx3c"
      },
      "outputs": [],
      "source": [
        "Adapt = Model(inputs=adapt.input, outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfOag8uIU1h0"
      },
      "outputs": [],
      "source": [
        "print(type(Adapt))\n",
        "Adapt.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7b7iez1BfR7"
      },
      "source": [
        "visualkeras installed to visualise neural network architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgeWoChPkDpY"
      },
      "outputs": [],
      "source": [
        "!pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwEUBeAUkL7G"
      },
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "# visualkeras.layered_view(Adapt, to_file='adapt_visual.png').show()\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "#plot_model(Adapt, show_shapes=True, to_file='adapt_visual.png', expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYGqc5VelZNU"
      },
      "outputs": [],
      "source": [
        "#from IPython.display import Image\n",
        "#Image(filename='adapt_visual.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j9bBYnwnEXG"
      },
      "outputs": [],
      "source": [
        "Adapt.save(\"adapt_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyQE0GYUpcTa"
      },
      "outputs": [],
      "source": [
        "# System-level installs (Graphviz binary and dependencies)\n",
        "!apt-get -qq install -y graphviz\n",
        "\n",
        "# Python packages\n",
        "!pip install -q graphviz pydot pydotplus visualkeras netron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hszvFzXgrRC6"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout\n",
        "\n",
        "base_model = ResNet50(input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in Adapt.layers[:100]:\n",
        "    layer.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "#    Dense(8, input_shape=(4,), activation='relu'),\n",
        "#    Dense(3, activation='softmax')\n",
        "])\n",
        "plot_model(model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4479yClvsc9s"
      },
      "outputs": [],
      "source": [
        "!pip install netron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AIg-Dhes0Pf"
      },
      "outputs": [],
      "source": [
        "Adapt.save(\"adapt_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmBxtiPWs3e6"
      },
      "outputs": [],
      "source": [
        "import netron\n",
        "netron.start(\"adapt_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z2Wqnlnth5U"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('adapt_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zQIkjf5fiNO"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktjtznR9gzcq"
      },
      "outputs": [],
      "source": [
        "#!dot -V"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8O2zQgier1N"
      },
      "outputs": [],
      "source": [
        "#from tensorflow.keras import Model\n",
        "\n",
        "# Example: Visualize only the first few layers\n",
        "#submodel = Model(inputs=Adapt.input, outputs=Adapt.layers[5].output)\n",
        "#visualkeras.layered_view(submodel, to_file='submodel.png').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1WN0Rw_axqQ"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zpL1iq3a3rO"
      },
      "outputs": [],
      "source": [
        "#import visualkeras\n",
        "#visualkeras.layered_view(Adapt, to_file='adapt_visual.png').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb5vJtmE_Zi1"
      },
      "outputs": [],
      "source": [
        "Adapt.save(\"adapt_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "we3fL0zmVTV5"
      },
      "outputs": [],
      "source": [
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.0001)\n",
        "checkpoint = ModelCheckpoint(\"model.h5\",monitor='val_accuracy',save_best_only=True,mode=\"auto\",verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK7wdH3LeUL1"
      },
      "outputs": [],
      "source": [
        "#mc = ModelCheckpoint('/content/gdrive/My Drive/best_model.h5', monitor='val_accuracy', mode='max')\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU7Iv7GYzCfh"
      },
      "outputs": [],
      "source": [
        "Adapt.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8s-d1ATj5wlR"
      },
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbqeS3qvecTs"
      },
      "outputs": [],
      "source": [
        "# epochs was previosuly 50.\n",
        "H = Adapt.fit(train_generator,validation_data=val_generator,epochs=20,verbose=1,callbacks=[learning_rate_reduction,checkpoint,early_stop], class_weight=class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIg5gv9se2_3"
      },
      "outputs": [],
      "source": [
        "def get_history_plots(epochs,Q):\n",
        "    # epochs = [R for R in range(epochs)]\n",
        "    fig , X = chart.subplots(1,2)\n",
        "    fig.set_size_inches(15,10)\n",
        "\n",
        "    X[0].plot([R for R in range(epochs)] , Q.history['accuracy'] ,'g' , label = 'Training Accuracy')\n",
        "    X[0].plot([R for R in range(epochs)] , Q.history['val_accuracy'] ,'r', label = 'Validation Accuracy')\n",
        "    X[0].set_title('Training & Validation Accuracy')\n",
        "    X[0].legend()\n",
        "    X[0].set_xlabel(\"Epochs\")\n",
        "    X[0].set_ylabel(\"Accuracy\")\n",
        "\n",
        "    X[1].plot([R for R in range(epochs)] , Q.history['loss'] , 'g' , label = 'Training Loss')\n",
        "    X[1].plot([R for R in range(epochs)] , Q.history['val_loss'] , 'r' , label = 'Validation Loss')\n",
        "    X[1].set_title('Training Accuracy & Loss')\n",
        "    X[1].legend()\n",
        "    X[1].set_xlabel(\"Epochs\")\n",
        "    X[1].set_ylabel(\"Training & Validation Loss\")\n",
        "    chart.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fum0gk8glRj"
      },
      "outputs": [],
      "source": [
        "get_history_plots(8,H)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoyBPbOVDn81"
      },
      "outputs": [],
      "source": [
        "#Adapt.evaluate(val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4DSO0boe_SW"
      },
      "outputs": [],
      "source": [
        "results = Adapt.evaluate(test_generator, steps=len(test_generator))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ULTvwjtfCez"
      },
      "outputs": [],
      "source": [
        "Y_pred = Adapt.predict(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfmBefFpuclU"
      },
      "outputs": [],
      "source": [
        "chart.figure(figsize=(10,6))\n",
        "sns.histplot(Y_pred, bins=50, color='blue')\n",
        "chart.title('Distribution of Predicted Probabilities')\n",
        "chart.xlabel('Predicted Probability of Pneumonia')\n",
        "chart.ylabel('Frequency')\n",
        "chart.grid(True)\n",
        "chart.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYmnqdMTfGIi"
      },
      "outputs": [],
      "source": [
        "#P = []\n",
        "#for Y in range(0,len(Y_pred)):\n",
        "  #if Y_pred[Y][0] >= 0.5:\n",
        "    #P.append(1)\n",
        "  #else:\n",
        "    #P.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayJ87RsVYPmw"
      },
      "outputs": [],
      "source": [
        "optimal_threshold = 0.5\n",
        "P = [] # Initialize P as an empty list\n",
        "for Y in range(0, len(Y_pred)):\n",
        "  if Y_pred[Y][0] >= optimal_threshold:\n",
        "    P.append(1)\n",
        "  else:\n",
        "    P.append(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GVr96RVyNQa"
      },
      "outputs": [],
      "source": [
        "y_true = test_generator.classes\n",
        "predictions = Adapt.predict(test_generator)\n",
        "\n",
        "auc_score = roc_auc_score(y_true, predictions)\n",
        "print(\"AUC_ROC Score:\", auc_score)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true, predictions)\n",
        "\n",
        "J = tpr - fpr\n",
        "optimal_idx = np.argmax(J)\n",
        "optimal_threshold = thresholds[optimal_idx]\n",
        "print(f\"Optimal Threshold from ROC Analysis: {optimal_threshold}\")\n",
        "\n",
        "chart.figure(figsize=(8,6))\n",
        "chart.plot(fpr, tpr, color='darkorange', label=f'AUC = {auc_score:.2f}')\n",
        "chart.plot([0, 1], [0, 1], color='navy', linestyle='--')\n",
        "chart.xlabel('False Positive Rate')\n",
        "chart.ylabel('True Positive Rate')\n",
        "chart.title('ROC Curve')\n",
        "chart.legend(loc='lower right')\n",
        "chart.grid(True)\n",
        "chart.tight_layout()\n",
        "chart.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fzHLlmZeG-F"
      },
      "outputs": [],
      "source": [
        "J = tpr -fpr\n",
        "optimal_idx = np.argmax(J)\n",
        "optimal_threshold = thresholds[optimal_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nw4ds-s1erg-"
      },
      "outputs": [],
      "source": [
        "# Get true labels from the test generator\n",
        "y_true = test_generator.classes\n",
        "\n",
        "# Get predictions from the model using the test generator\n",
        "predictions = Adapt.predict(test_generator)\n",
        "\n",
        "# Use the optimal threshold to get predicted classes\n",
        "y_pred_classes = (predictions > optimal_threshold).astype(np.int32) # Use np.int32 for consistency with Counter output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6IrpKbrfUA2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as chart\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_true, y_pred_classes, target_names=['NORMAL','PNEUMONIA'])) # Corrected target_names order\n",
        "\n",
        "# Calculate and plot the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "chart.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['NORMAL', 'PNEUMONIA'], yticklabels=['NORMAL', 'PNEUMONIA'])\n",
        "chart.xlabel('Predicted Label')\n",
        "chart.ylabel('True Label')\n",
        "chart.title('Confusion Matrix')\n",
        "chart.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}